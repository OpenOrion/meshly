{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba736f7c",
   "metadata": {},
   "source": [
    "# Extract and Reconstruct: Scientific Simulation Example\n",
    "\n",
    "This notebook demonstrates `Packable.extract()` and `reconstruct()` with a realistic scientific computing scenario:\n",
    "\n",
    "- A CFD simulation with mesh geometry and field data\n",
    "- Nested Pydantic classes containing Packables (Mesh)\n",
    "- Content-addressable storage for deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f850881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Optional, Dict, List\n",
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "from meshly import Mesh, Packable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ae1bf6",
   "metadata": {},
   "source": [
    "## 1. Define Scientific Data Structures\n",
    "\n",
    "We'll model a CFD simulation with:\n",
    "- `FieldData`: Scalar/vector field on the mesh (temperature, velocity, etc.)\n",
    "- `SimulationSnapshot`: A single timestep with mesh + fields\n",
    "- `SimulationCase`: Complete case with metadata and multiple snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349483ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data structures defined\n"
     ]
    }
   ],
   "source": [
    "class FieldData(BaseModel):\n",
    "    \"\"\"A field defined on mesh nodes or cells.\"\"\"\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    \n",
    "    name: str = Field(..., description=\"Field name (e.g., 'temperature', 'velocity')\")\n",
    "    field_type: str = Field(..., description=\"'scalar', 'vector', or 'tensor'\")\n",
    "    location: str = Field(\"node\", description=\"'node' or 'cell' centered\")\n",
    "    data: np.ndarray = Field(..., description=\"Field values\")\n",
    "    units: Optional[str] = Field(None, description=\"Physical units\")\n",
    "\n",
    "\n",
    "class SimulationSnapshot(BaseModel):\n",
    "    \"\"\"A single timestep of simulation data.\n",
    "    \n",
    "    Note: This is a regular Pydantic BaseModel (not Packable) that contains\n",
    "    a Mesh (which IS a Packable). This tests the nested Packable extraction.\n",
    "    \"\"\"\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    \n",
    "    time: float = Field(..., description=\"Simulation time\")\n",
    "    iteration: int = Field(..., description=\"Iteration number\")\n",
    "    mesh: Mesh = Field(..., description=\"Computational mesh\")\n",
    "    fields: Dict[str, FieldData] = Field(default_factory=dict, description=\"Field data\")\n",
    "    residuals: Optional[np.ndarray] = Field(None, description=\"Solver residuals\")\n",
    "\n",
    "\n",
    "class SimulationCase(BaseModel):\n",
    "    \"\"\"Complete simulation case with multiple snapshots.\"\"\"\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    \n",
    "    name: str = Field(..., description=\"Case name\")\n",
    "    description: str = Field(\"\", description=\"Case description\")\n",
    "    solver: str = Field(..., description=\"Solver name\")\n",
    "    parameters: Dict[str, float] = Field(default_factory=dict, description=\"Solver parameters\")\n",
    "    snapshots: List[SimulationSnapshot] = Field(default_factory=list, description=\"Time snapshots\")\n",
    "\n",
    "print(\"Data structures defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb88dff",
   "metadata": {},
   "source": [
    "## 2. Create Sample Simulation Data\n",
    "\n",
    "Let's create a simple 2D heat transfer simulation on a quad mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be109c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mesh: 25 vertices, 16 quads\n"
     ]
    }
   ],
   "source": [
    "# Create a simple 2D quad mesh (5x5 grid = 25 nodes, 16 quads)\n",
    "nx, ny = 5, 5\n",
    "x = np.linspace(0, 1, nx)\n",
    "y = np.linspace(0, 1, ny)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "vertices = np.column_stack([xx.ravel(), yy.ravel(), np.zeros(nx * ny)]).astype(np.float32)\n",
    "\n",
    "# Create quad indices\n",
    "quads = []\n",
    "for j in range(ny - 1):\n",
    "    for i in range(nx - 1):\n",
    "        n0 = j * nx + i\n",
    "        n1 = n0 + 1\n",
    "        n2 = n0 + nx + 1\n",
    "        n3 = n0 + nx\n",
    "        quads.append([n0, n1, n2, n3])\n",
    "\n",
    "indices = np.array(quads, dtype=np.uint32)\n",
    "\n",
    "mesh = Mesh(vertices=vertices, indices=indices)\n",
    "print(f\"Created mesh: {mesh.vertex_count} vertices, {len(indices)} quads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7588b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 snapshots\n",
      "  t=0.0: ['temperature', 'velocity']\n",
      "  t=0.1: ['temperature', 'velocity']\n",
      "  t=0.2: ['temperature', 'velocity']\n"
     ]
    }
   ],
   "source": [
    "# Create simulation snapshots at different times\n",
    "def create_snapshot(time: float, iteration: int, mesh: Mesh) -> SimulationSnapshot:\n",
    "    \"\"\"Create a snapshot with temperature and velocity fields.\"\"\"\n",
    "    n_nodes = mesh.vertex_count\n",
    "    coords = mesh.vertices[:, :2]  # x, y coordinates\n",
    "    \n",
    "    # Temperature: diffusing heat from center\n",
    "    center = np.array([0.5, 0.5])\n",
    "    r = np.linalg.norm(coords - center, axis=1)\n",
    "    temperature = 300 + 100 * np.exp(-r**2 / (0.1 + time)) \n",
    "    \n",
    "    # Velocity: rotating flow\n",
    "    vx = -(coords[:, 1] - 0.5)\n",
    "    vy = (coords[:, 0] - 0.5)\n",
    "    velocity = np.column_stack([vx, vy, np.zeros(n_nodes)]).astype(np.float32)\n",
    "    \n",
    "    # Residuals (solver convergence)\n",
    "    residuals = np.array([1e-3 / (iteration + 1), 1e-4 / (iteration + 1)], dtype=np.float32)\n",
    "    \n",
    "    return SimulationSnapshot(\n",
    "        time=time,\n",
    "        iteration=iteration,\n",
    "        mesh=mesh,\n",
    "        fields={\n",
    "            \"temperature\": FieldData(\n",
    "                name=\"temperature\",\n",
    "                field_type=\"scalar\",\n",
    "                location=\"node\",\n",
    "                data=temperature.astype(np.float32),\n",
    "                units=\"K\"\n",
    "            ),\n",
    "            \"velocity\": FieldData(\n",
    "                name=\"velocity\",\n",
    "                field_type=\"vector\",\n",
    "                location=\"node\",\n",
    "                data=velocity,\n",
    "                units=\"m/s\"\n",
    "            )\n",
    "        },\n",
    "        residuals=residuals\n",
    "    )\n",
    "\n",
    "# Create snapshots at t=0, 0.1, 0.2\n",
    "snapshots = [\n",
    "    create_snapshot(0.0, 0, mesh),\n",
    "    create_snapshot(0.1, 100, mesh),\n",
    "    create_snapshot(0.2, 200, mesh),\n",
    "]\n",
    "\n",
    "print(f\"Created {len(snapshots)} snapshots\")\n",
    "for s in snapshots:\n",
    "    print(f\"  t={s.time}: {list(s.fields.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93568d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation case: heat_transfer_2d\n",
      "  Solver: simpleFoam\n",
      "  Parameters: {'dt': 0.001, 'nu': 1e-05, 'alpha': 0.0001}\n",
      "  Snapshots: 3\n"
     ]
    }
   ],
   "source": [
    "# Create the complete simulation case\n",
    "case = SimulationCase(\n",
    "    name=\"heat_transfer_2d\",\n",
    "    description=\"2D heat transfer with rotating flow\",\n",
    "    solver=\"simpleFoam\",\n",
    "    parameters={\n",
    "        \"dt\": 0.001,\n",
    "        \"nu\": 1e-5,\n",
    "        \"alpha\": 1e-4,\n",
    "    },\n",
    "    snapshots=snapshots\n",
    ")\n",
    "\n",
    "print(f\"Simulation case: {case.name}\")\n",
    "print(f\"  Solver: {case.solver}\")\n",
    "print(f\"  Parameters: {case.parameters}\")\n",
    "print(f\"  Snapshots: {len(case.snapshots)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7048da",
   "metadata": {},
   "source": [
    "## 3. Extract the Simulation Data\n",
    "\n",
    "`Packable.extract()` recursively processes the nested structure:\n",
    "- Arrays → `{\"$ref\": checksum, \"$type\": \"array\"}`\n",
    "- Nested Mesh (Packable) → `{\"$ref\": checksum, \"$type\": \"packable\", ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95533188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data keys: ['name', 'description', 'solver', 'parameters', 'snapshots']\n",
      "\n",
      "Total assets: 8\n",
      "\n",
      "Asset sizes:\n",
      "  4e71a79c2d0fa381: 1,467 bytes\n",
      "  28dc719a0c8c1387: 200 bytes\n",
      "  59ffdd6bfac7876a: 250 bytes\n",
      "  0c345962a52e7e2c: 133 bytes\n",
      "  292cfc23f6777b02: 200 bytes\n",
      "  17b38a2f2cbdd0a7: 133 bytes\n",
      "  145838c08771e6ef: 201 bytes\n",
      "  ea37b2590dba4b31: 132 bytes\n"
     ]
    }
   ],
   "source": [
    "# Extract the entire simulation case\n",
    "extracted = Packable.extract(case)\n",
    "\n",
    "print(f\"Extracted data keys: {list(extracted.data.keys())}\")\n",
    "print(f\"\\nTotal assets: {len(extracted.assets)}\")\n",
    "print(f\"\\nAsset sizes:\")\n",
    "for checksum, data in extracted.assets.items():\n",
    "    print(f\"  {checksum}: {len(data):,} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba82742d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data structure:\n",
      "{\n",
      "  \"name\": \"heat_transfer_2d\",\n",
      "  \"description\": \"2D heat transfer with rotating flow\",\n",
      "  \"solver\": \"simpleFoam\",\n",
      "  \"parameters\": {\n",
      "    \"dt\": 0.001,\n",
      "    \"nu\": 1e-05,\n",
      "    \"alpha\": 0.0001\n",
      "  },\n",
      "  \"snapshots\": [\n",
      "    {\n",
      "      \"time\": 0.0,\n",
      "      \"iteration\": 0,\n",
      "      \"mesh\": {\n",
      "        \"$ref\": \"4e71a79c2d0fa381\"\n",
      "      },\n",
      "      \"fields\": {\n",
      "        \"temperature\": {\n",
      "          \"name\": \"temperature\",\n",
      "          \"field_type\": \"scalar\",\n",
      "          \"location\": \"node\",\n",
      "          \"data\": {\n",
      "            \"$ref\": \"28dc719a0c8c1387\"\n",
      "          },\n",
      "          \"units\": \"K\"\n",
      "        },\n",
      "        \"velocity\": {\n",
      "          \"name\": \"velocity\",\n",
      "          \"field_type\": \"vector\",\n",
      "          \"location\": \"node\",\n",
      "          \"data\": {\n",
      "            \"$ref\": \"59ffdd6bfac7876a\"\n",
      "          },\n",
      "          \"units\": \"m/s\"\n",
      "        }\n",
      "      },\n",
      "      \"residuals\": {\n",
      "        \"$ref\": \"0c345962a52e7e2c\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"time\": 0.1,\n",
      "      \"iteration\": 100,\n",
      "      \"mesh\": {\n",
      "        \"$ref\": \"4e71a79c2d0fa381\"\n",
      "      },\n",
      "      \"fields\": {\n",
      "        \"temperature\": {\n",
      "          \"name\": \"temperature\",\n",
      "          \"field_type\": \"scalar\",\n",
      "          \"location\": \"node\",\n",
      "          \"data\": {\n",
      "            \"$ref\": \"292cfc23f6777b02\"\n",
      "          },\n",
      "          \"units\": \"K\"\n",
      "        },\n",
      "        \"velocity\": {\n",
      "          \"name\": \"velocity\",\n",
      "          \"field_type\": \"vector\",\n",
      "          \"location\": \"node\",\n",
      "          \"data\": {\n",
      "            \"$ref\": \"59ffdd6bfac7876a\"\n",
      "          },\n",
      "          \"units\": \"m/s\"\n",
      "        }\n",
      "      },\n",
      "      \"residuals\": {\n",
      "        \"$ref\": \"17b38a2f2cbdd0a7\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"time\": 0.2,\n",
      "      \"iteration\": 200,\n",
      "      \"mesh\": {\n",
      "        \"$ref\": \"4e71a79c2d0fa381\"\n",
      "      },\n",
      "      \"fields\": {\n",
      "        \"temperature\": {\n",
      "          \"name\": \"temperature\",\n",
      "          \"field_type\": \"scalar\",\n",
      "          \"location\": \"node\",\n",
      "          \"data\": {\n",
      "            \"$ref\": \"145838c08771e6ef\"\n",
      "          },\n",
      "          \"units\": \"K\"\n",
      "        },\n",
      "        \"velocity\": {\n",
      "          \"name\": \"velocity\",\n",
      "          \"field_type\": \"vector\",\n",
      "          \"location\": \"node\",\n",
      "       \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Examine the extracted data structure\n",
    "import json\n",
    "\n",
    "# Pretty print the extracted data (it's JSON-serializable!)\n",
    "print(\"Extracted data structure:\")\n",
    "print(json.dumps(extracted.data, indent=2)[:2000] + \"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6977cb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh reference: {'$ref': '4e71a79c2d0fa381'}\n"
     ]
    }
   ],
   "source": [
    "# Look at the first snapshot's mesh reference\n",
    "mesh_ref = extracted.data[\"snapshots\"][0][\"mesh\"]\n",
    "print(f\"Mesh reference: {mesh_ref}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc82716a",
   "metadata": {},
   "source": [
    "## 4. Asset Deduplication\n",
    "\n",
    "Since all snapshots share the same mesh, it's only stored once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a251ef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh checksums: ['4e71a79c2d0fa381', '4e71a79c2d0fa381', '4e71a79c2d0fa381']\n",
      "\n",
      "All same? True\n",
      "\n",
      "The mesh is stored only ONCE in assets, saving 2,934 bytes!\n"
     ]
    }
   ],
   "source": [
    "# Check mesh references across snapshots\n",
    "mesh_refs = [s[\"mesh\"][\"$ref\"] for s in extracted.data[\"snapshots\"]]\n",
    "print(f\"Mesh checksums: {mesh_refs}\")\n",
    "print(f\"\\nAll same? {len(set(mesh_refs)) == 1}\")\n",
    "print(f\"\\nThe mesh is stored only ONCE in assets, saving {(len(mesh_refs)-1) * len(extracted.assets[mesh_refs[0]]):,} bytes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b732526c",
   "metadata": {},
   "source": [
    "## 5. Reconstruct back to SimulationCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c3761f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reconstructed case: heat_transfer_2d with 3 snapshots\n",
      "Decoded mesh from reconstructed case: 25 vertices, 64 indices\n"
     ]
    }
   ],
   "source": [
    "reconstructed_case = Packable.reconstruct(SimulationCase, extracted.data, extracted.assets)\n",
    "print(f\"\\nReconstructed case: {reconstructed_case.name} with {len(reconstructed_case.snapshots)} snapshots\")\n",
    "\n",
    "decoded_mesh = Mesh.decode(reconstructed_case.snapshots[0].mesh.encode())\n",
    "print(f\"Decoded mesh from reconstructed case: {decoded_mesh.vertex_count} vertices, {len(decoded_mesh.indices)} indices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf56b9",
   "metadata": {},
   "source": [
    "## 6. Lazy Loading with CachedAssetLoader\n",
    "\n",
    "When working with large datasets, you may want to:\n",
    "- Load assets on-demand (lazy loading)\n",
    "- Cache fetched assets to disk for subsequent runs\n",
    "\n",
    "`Packable.reconstruct()` supports this via `CachedAssetLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac9c08e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Lazy loading with callable ===\n",
      "\n",
      "LazyModel created, no assets fetched yet. Fetch count: 0\n",
      "Type: <class 'meshly.packable.LazyModel'>\n",
      "\n",
      "Case name: heat_transfer_2d\n",
      "Fetch count after accessing name: 0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from meshly.packable import CachedAssetLoader\n",
    "from meshly.data_handler import DataHandler\n",
    "\n",
    "# Simulate fetching assets from remote storage\n",
    "fetch_count = [0]\n",
    "\n",
    "def fetch_from_storage(checksum: str) -> bytes:\n",
    "    \"\"\"Simulate fetching from cloud/remote storage.\"\"\"\n",
    "    fetch_count[0] += 1\n",
    "    print(f\"  Fetching asset {checksum[:8]}... (fetch #{fetch_count[0]})\")\n",
    "    return extracted.assets[checksum]\n",
    "\n",
    "# Using a plain callable - lazy loading, assets fetched on field access\n",
    "print(\"=== Lazy loading with callable ===\")\n",
    "lazy_case = Packable.reconstruct(SimulationCase, extracted.data, fetch_from_storage)\n",
    "\n",
    "print(f\"\\nLazyModel created, no assets fetched yet. Fetch count: {fetch_count[0]}\")\n",
    "print(f\"Type: {type(lazy_case)}\")\n",
    "\n",
    "# Access primitive fields - no fetch needed\n",
    "print(f\"\\nCase name: {lazy_case.name}\")\n",
    "print(f\"Fetch count after accessing name: {fetch_count[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38bd4003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Accessing first snapshot ===\n",
      "  Fetching asset 4e71a79c... (fetch #1)\n",
      "  Fetching asset 28dc719a... (fetch #2)\n",
      "  Fetching asset 59ffdd6b... (fetch #3)\n",
      "  Fetching asset 0c345962... (fetch #4)\n",
      "  Fetching asset 4e71a79c... (fetch #5)\n",
      "  Fetching asset 292cfc23... (fetch #6)\n",
      "  Fetching asset 59ffdd6b... (fetch #7)\n",
      "  Fetching asset 17b38a2f... (fetch #8)\n",
      "  Fetching asset 4e71a79c... (fetch #9)\n",
      "  Fetching asset 145838c0... (fetch #10)\n",
      "  Fetching asset 59ffdd6b... (fetch #11)\n",
      "  Fetching asset ea37b259... (fetch #12)\n",
      "Fetch count after accessing snapshots: 12\n",
      "\n",
      "Snapshot time: 0.0\n",
      "Mesh vertices shape: (25, 3)\n",
      "\n",
      "=== Resolving to full model ===\n",
      "Final fetch count: 12\n",
      "Resolved type: <class '__main__.SimulationCase'>\n"
     ]
    }
   ],
   "source": [
    "# Access a snapshot - this triggers fetching of nested assets\n",
    "print(\"=== Accessing first snapshot ===\")\n",
    "snapshot = lazy_case.snapshots[0]\n",
    "print(f\"Fetch count after accessing snapshots: {fetch_count[0]}\")\n",
    "\n",
    "# The mesh is fetched when we access it\n",
    "print(f\"\\nSnapshot time: {snapshot.time}\")\n",
    "print(f\"Mesh vertices shape: {snapshot.mesh.vertices.shape}\")\n",
    "\n",
    "# To fully resolve and get the actual Pydantic model:\n",
    "print(\"\\n=== Resolving to full model ===\")\n",
    "resolved_case = lazy_case.resolve()\n",
    "print(f\"Final fetch count: {fetch_count[0]}\")\n",
    "print(f\"Resolved type: {type(resolved_case)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d7b7c0",
   "metadata": {},
   "source": [
    "### CachedAssetLoader: Persistent Disk Cache\n",
    "\n",
    "For repeated access, use `CachedAssetLoader` to cache fetched assets to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88d9c7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First run: fetching and caching ===\n",
      "  Fetching asset 4e71a79c... (fetch #1)\n",
      "  Fetching asset 28dc719a... (fetch #2)\n",
      "  Fetching asset 59ffdd6b... (fetch #3)\n",
      "  Fetching asset 0c345962... (fetch #4)\n",
      "  Fetching asset 292cfc23... (fetch #5)\n",
      "  Fetching asset 17b38a2f... (fetch #6)\n",
      "  Fetching asset 145838c0... (fetch #7)\n",
      "  Fetching asset ea37b259... (fetch #8)\n",
      "Assets fetched: 8\n",
      "\n",
      "=== Second run: reading from cache ===\n",
      "Assets fetched from remote: 0 (all served from cache!)\n",
      "Resolved case: heat_transfer_2d with 3 snapshots\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "# Reset fetch counter\n",
    "fetch_count[0] = 0\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    cache_path = Path(tmpdir) / \"asset_cache\"\n",
    "    \n",
    "    # Create cache handler and loader\n",
    "    cache_handler = DataHandler.create(cache_path)\n",
    "    loader = CachedAssetLoader(fetch=fetch_from_storage, cache=cache_handler)\n",
    "    \n",
    "    print(\"=== First run: fetching and caching ===\")\n",
    "    lazy1 = Packable.reconstruct(SimulationCase, extracted.data, loader)\n",
    "    _ = lazy1.resolve()  # Fetch all assets\n",
    "    print(f\"Assets fetched: {fetch_count[0]}\")\n",
    "    \n",
    "    # Finalize to persist cache\n",
    "    cache_handler.finalize()\n",
    "    \n",
    "    # Second run with same cache location\n",
    "    print(\"\\n=== Second run: reading from cache ===\")\n",
    "    fetch_count[0] = 0\n",
    "    cache_handler2 = DataHandler.create(cache_path)\n",
    "    loader2 = CachedAssetLoader(fetch=fetch_from_storage, cache=cache_handler2)\n",
    "    \n",
    "    lazy2 = Packable.reconstruct(SimulationCase, extracted.data, loader2)\n",
    "    resolved2 = lazy2.resolve()\n",
    "    print(f\"Assets fetched from remote: {fetch_count[0]} (all served from cache!)\")\n",
    "    print(f\"Resolved case: {resolved2.name} with {len(resolved2.snapshots)} snapshots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a54dcde",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "`Packable.extract()` is a **static method** that handles:\n",
    "\n",
    "| Input | Handling |\n",
    "|-------|----------|\n",
    "| Top-level Packable | Expands fields, arrays → refs |\n",
    "| Nested Packable (in dict/list/BaseModel) | Becomes `{\"$ref\": ..., \"$type\": \"packable\"}` |\n",
    "| NumPy arrays | Becomes `{\"$ref\": ..., \"$type\": \"array\"}` |\n",
    "| BaseModel | Preserves structure with `__model_class__` |\n",
    "| Primitives | Passed through unchanged |\n",
    "\n",
    "`Packable.reconstruct()` supports three modes:\n",
    "\n",
    "| AssetProvider | Result | Use Case |\n",
    "|--------------|--------|----------|\n",
    "| `Dict[str, bytes]` | `TModel` | Eager loading, all assets in memory |\n",
    "| `AssetFetcher` | `LazyModel[TModel]` | Lazy per-field loading |\n",
    "| `CachedAssetLoader` | `LazyModel[TModel]` | Lazy loading with disk cache |\n",
    "\n",
    "Key benefits for scientific computing:\n",
    "- **Deduplication**: Shared meshes/arrays stored once\n",
    "- **Lazy loading**: Load only the fields you need with `LazyModel`\n",
    "- **Persistent caching**: `CachedAssetLoader` caches fetched assets to disk\n",
    "- **JSON metadata**: Easy to query/index simulation cases\n",
    "- **Version control friendly**: Small metadata files, large binary assets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
