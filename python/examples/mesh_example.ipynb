{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic-based Mesh Example\n",
    "\n",
    "This notebook demonstrates how to use the new Pydantic-based Mesh class in meshly. It covers:\n",
    "\n",
    "1. Creating custom Mesh subclasses with additional attributes\n",
    "2. Working with numpy arrays in Pydantic models\n",
    "3. Encoding and decoding meshes to/from zip files\n",
    "4. Optimizing meshes with the built-in optimization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Import the Mesh class\n",
    "from meshly import Mesh\n",
    "from pydantic import Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a Custom Mesh Subclass\n",
    "\n",
    "One of the key benefits of the new Pydantic-based Mesh class is the ability to create custom subclasses with additional attributes. Let's create a `TexturedMesh` class that adds texture coordinates and normals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meshly import Packable\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "\n",
    "\n",
    "class MaterialProperties(BaseModel):\n",
    "    \"\"\"Material properties with numpy arrays - demonstrates BaseModel in dict edge case.\"\"\"\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "    name: str = Field(..., description=\"Material name\")\n",
    "    diffuse: np.ndarray = Field(..., description=\"Diffuse color array\")\n",
    "    specular: np.ndarray = Field(..., description=\"Specular color array\")\n",
    "    shininess: float = Field(32.0, description=\"Shininess value\")\n",
    "\n",
    "\n",
    "class PhysicsProperties(Packable):\n",
    "    \"\"\"Physics properties as a nested Packable - demonstrates Packable field support.\"\"\"\n",
    "    mass: float = Field(1.0, description=\"Object mass\")\n",
    "    friction: float = Field(0.5, description=\"Friction coefficient\")\n",
    "    # Arrays in nested Packable are encoded/decoded using the Packable's own encode/decode\n",
    "    inertia_tensor: np.ndarray = Field(..., description=\"3x3 inertia tensor\")\n",
    "    collision_points: np.ndarray = Field(..., description=\"Collision sample points\")\n",
    "\n",
    "\n",
    "class TexturedMesh(Mesh):\n",
    "    \"\"\"\n",
    "    A mesh with texture coordinates and normals.\n",
    "    \n",
    "    This demonstrates how to create a custom Mesh subclass with additional\n",
    "    numpy array attributes that will be automatically encoded/decoded.\n",
    "    \"\"\"\n",
    "    # Add texture coordinates and normals as additional numpy arrays\n",
    "    texture_coords: np.ndarray = Field(..., description=\"Texture coordinates\")\n",
    "    normals: np.ndarray | None = Field(None, description=\"Vertex normals\")\n",
    "\n",
    "    # Add non-array attributes\n",
    "    material_name: str = Field(\"default\", description=\"Material name\")\n",
    "    tags: list[str] = Field(default_factory=list, description=\"Tags for the mesh\")\n",
    "\n",
    "    # Dictionary containing nested dictionaries with arrays\n",
    "    material_data: dict[str, dict[str, np.ndarray]] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Nested dictionary structure with arrays\"\n",
    "    )\n",
    "\n",
    "    material_colors: dict[str, str] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Dictionary with non-array values\"\n",
    "    )\n",
    "\n",
    "    # Dictionary containing BaseModel instances with numpy arrays\n",
    "    # This demonstrates the edge case of dict[str, BaseModel] where BaseModel has arrays\n",
    "    materials: dict[str, MaterialProperties] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Dictionary of material name to MaterialProperties (BaseModel with arrays)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating a Mesh Instance\n",
    "\n",
    "Now let's create a simple cube mesh with texture coordinates and normals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh created with 8 vertices and 36 indices\n",
      "Material name: cube_material\n",
      "Tags: ['cube', 'example']\n",
      "Materials (BaseModel dict): ['cube_material', 'secondary_material']\n"
     ]
    }
   ],
   "source": [
    "# Create vertices for a cube\n",
    "vertices = np.array([\n",
    "    [-0.5, -0.5, -0.5],  # 0: bottom-left-back\n",
    "    [0.5, -0.5, -0.5],   # 1: bottom-right-back\n",
    "    [0.5, 0.5, -0.5],    # 2: top-right-back\n",
    "    [-0.5, 0.5, -0.5],   # 3: top-left-back\n",
    "    [-0.5, -0.5, 0.5],   # 4: bottom-left-front\n",
    "    [0.5, -0.5, 0.5],    # 5: bottom-right-front\n",
    "    [0.5, 0.5, 0.5],     # 6: top-right-front\n",
    "    [-0.5, 0.5, 0.5]     # 7: top-left-front\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Create indices for the cube\n",
    "indices = np.array([\n",
    "    [0, 1, 2, 2, 3, 0],  # back face\n",
    "    [1, 5, 6, 6, 2, 1],  # right face\n",
    "    [5, 4, 7, 7, 6, 5],  # front face\n",
    "    [4, 0, 3, 3, 7, 4],  # left face\n",
    "    [3, 2, 6, 6, 7, 3],  # top face\n",
    "    [4, 5, 1, 1, 0, 4]   # bottom face\n",
    "], dtype=np.uint32)\n",
    "\n",
    "# Create texture coordinates (one for each vertex)\n",
    "texture_coords = np.array([\n",
    "    [0.0, 0.0],  # 0\n",
    "    [1.0, 0.0],  # 1\n",
    "    [1.0, 1.0],  # 2\n",
    "    [0.0, 1.0],  # 3\n",
    "    [0.0, 0.0],  # 4\n",
    "    [1.0, 0.0],  # 5\n",
    "    [1.0, 1.0],  # 6\n",
    "    [0.0, 1.0]   # 7\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Create normals (one for each vertex)\n",
    "normals = np.array([\n",
    "    [0.0, 0.0, -1.0],  # 0: back\n",
    "    [0.0, 0.0, -1.0],  # 1: back\n",
    "    [0.0, 0.0, -1.0],  # 2: back\n",
    "    [0.0, 0.0, -1.0],  # 3: back\n",
    "    [0.0, 0.0, 1.0],   # 4: front\n",
    "    [0.0, 0.0, 1.0],   # 5: front\n",
    "    [0.0, 0.0, 1.0],   # 6: front\n",
    "    [0.0, 0.0, 1.0]    # 7: front\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Create MaterialProperties instances (BaseModel with numpy arrays)\n",
    "cube_material = MaterialProperties(\n",
    "    name=\"cube_material\",\n",
    "    diffuse=np.array([1.0, 0.5, 0.31], dtype=np.float32),\n",
    "    specular=np.array([0.5, 0.5, 0.5], dtype=np.float32),\n",
    "    shininess=32.0\n",
    ")\n",
    "\n",
    "secondary_material = MaterialProperties(\n",
    "    name=\"secondary_material\",\n",
    "    diffuse=np.array([0.2, 0.8, 0.2], dtype=np.float32),\n",
    "    specular=np.array([0.3, 0.3, 0.3], dtype=np.float32),\n",
    "    shininess=16.0\n",
    ")\n",
    "\n",
    "# Create PhysicsProperties instance (nested Packable)\n",
    "physics = PhysicsProperties(\n",
    "    mass=2.5,\n",
    "    friction=0.7,\n",
    "    inertia_tensor=np.eye(3, dtype=np.float32) * 0.1,  # 3x3 identity scaled\n",
    "    collision_points=np.array([\n",
    "        [-0.5, -0.5, -0.5],\n",
    "        [0.5, 0.5, 0.5],\n",
    "        [0.0, 0.0, 0.0]\n",
    "    ], dtype=np.float32)\n",
    ")\n",
    "\n",
    "# Create the textured mesh\n",
    "mesh = TexturedMesh(\n",
    "    vertices=vertices,\n",
    "    indices=indices,\n",
    "    texture_coords=texture_coords,\n",
    "    normals=normals,\n",
    "    material_name=\"cube_material\",\n",
    "    tags=[\"cube\", \"example\"],\n",
    "    material_data={\n",
    "        \"cube_material\": {\n",
    "            \"diffuse\": np.array([1.0, 0.5, 0.31], dtype=np.float32),\n",
    "            \"specular\": np.array([0.5, 0.5, 0.5], dtype=np.float32),\n",
    "            \"shininess\": np.array([32.0], dtype=np.float32)\n",
    "        }\n",
    "    },\n",
    "    material_colors={\n",
    "        \"cube_material\": \"#FF7F50\"\n",
    "    },\n",
    "    # dict[str, BaseModel] with numpy arrays inside\n",
    "    materials={\n",
    "        \"cube_material\": cube_material,\n",
    "        \"secondary_material\": secondary_material\n",
    "    },\n",
    "    # Nested Packable field\n",
    "    physics=physics\n",
    ")\n",
    "\n",
    "print(f\"Mesh created with {mesh.vertex_count} vertices and {mesh.index_count} indices\")\n",
    "print(f\"Material name: {mesh.material_name}\")\n",
    "print(f\"Tags: {mesh.tags}\")\n",
    "print(f\"Materials (BaseModel dict): {list(mesh.materials.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimizing the Mesh\n",
    "\n",
    "The Mesh class provides several optimization methods that can be used to improve rendering performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized for vertex cache\n",
      "Optimized for overdraw\n",
      "Optimized for vertex fetch\n"
     ]
    }
   ],
   "source": [
    "# Optimize the mesh for vertex cache\n",
    "vertex_cache_optimized_mesh = mesh.optimize_vertex_cache()\n",
    "print(\"Optimized for vertex cache\")\n",
    "\n",
    "# Optimize the mesh for overdraw\n",
    "overdraw_optimized_mesh = mesh.optimize_overdraw()\n",
    "print(\"Optimized for overdraw\")\n",
    "\n",
    "# Optimize the mesh for vertex fetch\n",
    "vertex_fetch_optimized = mesh.optimize_vertex_fetch()\n",
    "print(\"Optimized for vertex fetch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Encoding and Saving the Mesh\n",
    "\n",
    "The Mesh class provides methods for encoding the mesh and saving it to a zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mesh to textured_cube.zip has 8 vertices and 36 indices\n",
      "Decoded mesh has 8 vertices and 36 indices\n"
     ]
    }
   ],
   "source": [
    "# Save the mesh to a zip file\n",
    "zip_path = Path(\"textured_cube.zip\")\n",
    "mesh.save_to_zip(zip_path)\n",
    "assert zip_path.exists()\n",
    "print(f\"Saved mesh to {zip_path} has {mesh.vertex_count} vertices and {mesh.index_count} indices\")\n",
    "\n",
    "\n",
    "decoded_mesh = Mesh.decode(mesh.encode())\n",
    "print(f\"Decoded mesh has {decoded_mesh.vertex_count} vertices and {decoded_mesh.index_count} indices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loading the Mesh from a Zip File\n",
    "\n",
    "The Mesh class provides a class method for loading a mesh from a zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mesh: 8 vertices, 36 indices\n",
      "Material name: cube_material\n",
      "Tags: ['cube', 'example']\n",
      "\n",
      "Texture coordinates shape: (8, 2)\n",
      "Normals shape: (8, 3)\n",
      "Material data: {'cube_material': {'diffuse': array([1.  , 0.5 , 0.31], dtype=float32), 'shininess': array([32.], dtype=float32), 'specular': array([0.5, 0.5, 0.5], dtype=float32)}}\n",
      "Material colors: {'cube_material': '#FF7F50'}\n",
      "\n",
      "--- BaseModel dict edge case ---\n",
      "Materials keys: ['cube_material', 'secondary_material']\n",
      "  cube_material:\n",
      "    type: MaterialProperties\n",
      "    diffuse: [1.   0.5  0.31]\n",
      "    specular: [0.5 0.5 0.5]\n",
      "    shininess: 32.0\n",
      "  secondary_material:\n",
      "    type: MaterialProperties\n",
      "    diffuse: [0.2 0.8 0.2]\n",
      "    specular: [0.3 0.3 0.3]\n",
      "    shininess: 16.0\n"
     ]
    }
   ],
   "source": [
    "# Load the mesh from the zip file\n",
    "loaded_mesh = TexturedMesh.load_from_zip(zip_path)\n",
    "print(f\"Loaded mesh: {loaded_mesh.vertex_count} vertices, {loaded_mesh.index_count} indices\")\n",
    "print(f\"Material name: {loaded_mesh.material_name}\")\n",
    "print(f\"Tags: {loaded_mesh.tags}\")\n",
    "\n",
    "# Verify that the texture coordinates and normals were loaded correctly\n",
    "print(f\"\\nTexture coordinates shape: {loaded_mesh.texture_coords.shape}\")\n",
    "print(f\"Normals shape: {loaded_mesh.normals.shape}\")\n",
    "print(f\"Material data: {loaded_mesh.material_data}\")\n",
    "print(f\"Material colors: {loaded_mesh.material_colors}\")\n",
    "\n",
    "# Verify the dict[str, BaseModel] edge case was loaded correctly\n",
    "print(\"\\n--- BaseModel dict edge case ---\")\n",
    "print(f\"Materials keys: {list(loaded_mesh.materials.keys())}\")\n",
    "for mat_name, mat in loaded_mesh.materials.items():\n",
    "    print(f\"  {mat_name}:\")\n",
    "    print(f\"    type: {type(mat).__name__}\")\n",
    "    print(f\"    diffuse: {mat.diffuse}\")\n",
    "    print(f\"    specular: {mat.specular}\")\n",
    "    print(f\"    shininess: {mat.shininess}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating a Different Mesh Subclass\n",
    "\n",
    "Let's create another mesh subclass with different attributes to demonstrate the flexibility of the Pydantic-based Mesh class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skinned mesh created with 8 vertices and 36 indices\n",
      "Skeleton name: human_skeleton\n",
      "Animation names: ['walk', 'run', 'jump']\n",
      "Bone weights shape: (8, 4)\n",
      "Bone indices shape: (8, 4)\n"
     ]
    }
   ],
   "source": [
    "class SkinnedMesh(Mesh):\n",
    "    \"\"\"\n",
    "    A mesh with skinning information for animation.\n",
    "    \"\"\"\n",
    "    # Add bone weights and indices as additional numpy arrays\n",
    "    bone_weights: np.ndarray = Field(..., description=\"Bone weights for each vertex\")\n",
    "    bone_indices: np.ndarray = Field(..., description=\"Bone indices for each vertex\")\n",
    "\n",
    "    # Add non-array attributes\n",
    "    skeleton_name: str = Field(\"default\", description=\"Skeleton name\")\n",
    "    animation_names: list[str] = Field(default_factory=list, description=\"Animation names\")\n",
    "\n",
    "# Create a simple skinned mesh\n",
    "skinned_mesh = SkinnedMesh(\n",
    "    vertices=vertices,\n",
    "    indices=indices,\n",
    "    bone_weights=np.random.random((len(vertices), 4)).astype(np.float32),  # 4 weights per vertex\n",
    "    bone_indices=np.random.randint(0, 4, (len(vertices), 4)).astype(np.uint8),  # 4 bone indices per vertex\n",
    "    skeleton_name=\"human_skeleton\",\n",
    "    animation_names=[\"walk\", \"run\", \"jump\"]\n",
    ")\n",
    "\n",
    "print(f\"Skinned mesh created with {skinned_mesh.vertex_count} vertices and {skinned_mesh.index_count} indices\")\n",
    "print(f\"Skeleton name: {skinned_mesh.skeleton_name}\")\n",
    "print(f\"Animation names: {skinned_mesh.animation_names}\")\n",
    "print(f\"Bone weights shape: {skinned_mesh.bone_weights.shape}\")\n",
    "print(f\"Bone indices shape: {skinned_mesh.bone_indices.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Saving and Loading the Skinned Mesh\n",
    "\n",
    "Let's save and load the skinned mesh to demonstrate that all attributes are preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved skinned mesh to skinned_cube.zip, file size: 2498 bytes\n",
      "\n",
      "Loaded skinned mesh: 8 vertices, 36 indices\n",
      "Skeleton name: human_skeleton\n",
      "Animation names: ['walk', 'run', 'jump']\n",
      "Bone weights shape: (8, 4)\n",
      "Bone indices shape: (8, 4)\n"
     ]
    }
   ],
   "source": [
    "# Save the skinned mesh to a zip file\n",
    "skinned_zip_path = Path(\"skinned_cube.zip\")\n",
    "skinned_mesh.save_to_zip(skinned_zip_path)\n",
    "print(f\"Saved skinned mesh to {skinned_zip_path}, file size: {skinned_zip_path.stat().st_size} bytes\")\n",
    "\n",
    "# Load the skinned mesh from the zip file\n",
    "loaded_skinned_mesh = SkinnedMesh.load_from_zip(skinned_zip_path)\n",
    "print(f\"\\nLoaded skinned mesh: {loaded_skinned_mesh.vertex_count} vertices, {loaded_skinned_mesh.index_count} indices\")\n",
    "print(f\"Skeleton name: {loaded_skinned_mesh.skeleton_name}\")\n",
    "print(f\"Animation names: {loaded_skinned_mesh.animation_names}\")\n",
    "print(f\"Bone weights shape: {loaded_skinned_mesh.bone_weights.shape}\")\n",
    "print(f\"Bone indices shape: {loaded_skinned_mesh.bone_indices.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleaning Up (Part 1)\n",
    "\n",
    "Let's clean up the files we created so far before the cache examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed textured_cube.zip\n",
      "Removed skinned_cube.zip\n",
      "\n",
      "Sections 1-8 completed!\n"
     ]
    }
   ],
   "source": [
    "# Clean up files from sections 1-7\n",
    "for path in [zip_path, skinned_zip_path]:\n",
    "    if Path(path).exists():\n",
    "        Path(path).unlink()\n",
    "        print(f\"Removed {path}\")\n",
    "\n",
    "print(\"\\nSections 1-8 completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Nested Packables with Direct Fields\n",
    "\n",
    "Now that Packables support nested Packable fields directly, let's demonstrate saving and loading a mesh with a nested `PhysicsProperties` Packable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created mesh with nested physics Packable\n",
      "  Mass: 5.0\n",
      "  Friction: 0.3\n",
      "  Inertia tensor shape: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create a mesh subclass with a nested Packable field\n",
    "class MeshWithPhysics(Mesh):\n",
    "    \"\"\"A mesh with embedded physics properties as a nested Packable.\"\"\"\n",
    "    physics: PhysicsProperties | None = Field(None, description=\"Physics properties\")\n",
    "    label: str = Field(\"default\", description=\"Mesh label\")\n",
    "\n",
    "# Create physics properties\n",
    "physics_props = PhysicsProperties(\n",
    "    mass=5.0,\n",
    "    friction=0.3,\n",
    "    inertia_tensor=np.diag([1.0, 2.0, 3.0]).astype(np.float32),\n",
    "    collision_points=vertices.copy()  # Use cube vertices as collision points\n",
    ")\n",
    "\n",
    "# Create mesh with nested Packable\n",
    "mesh_with_physics = MeshWithPhysics(\n",
    "    vertices=vertices,\n",
    "    indices=indices,\n",
    "    physics=physics_props,\n",
    "    label=\"physics_cube\"\n",
    ")\n",
    "\n",
    "print(f\"Created mesh with nested physics Packable\")\n",
    "print(f\"  Mass: {mesh_with_physics.physics.mass}\")\n",
    "print(f\"  Friction: {mesh_with_physics.physics.friction}\")\n",
    "print(f\"  Inertia tensor shape: {mesh_with_physics.physics.inertia_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mesh with nested Packable:\n",
      "  Label: physics_cube\n",
      "  Vertices: 8\n",
      "  Physics mass: 5.0\n",
      "  Physics friction: 0.3\n",
      "  Inertia tensor:\n",
      "[[1. 0. 0.]\n",
      " [0. 2. 0.]\n",
      " [0. 0. 3.]]\n",
      "✓ Collision points match!\n"
     ]
    }
   ],
   "source": [
    "# Save and load the mesh with nested Packable\n",
    "physics_zip_path = Path(\"./mesh_with_physics.zip\")\n",
    "mesh_with_physics.save_to_zip(physics_zip_path)\n",
    "\n",
    "loaded_physics_mesh = MeshWithPhysics.load_from_zip(physics_zip_path)\n",
    "\n",
    "print(\"Loaded mesh with nested Packable:\")\n",
    "print(f\"  Label: {loaded_physics_mesh.label}\")\n",
    "print(f\"  Vertices: {loaded_physics_mesh.vertex_count}\")\n",
    "print(f\"  Physics mass: {loaded_physics_mesh.physics.mass}\")\n",
    "print(f\"  Physics friction: {loaded_physics_mesh.physics.friction}\")\n",
    "print(f\"  Inertia tensor:\\n{loaded_physics_mesh.physics.inertia_tensor}\")\n",
    "np.testing.assert_array_almost_equal(\n",
    "    loaded_physics_mesh.physics.collision_points, \n",
    "    physics_props.collision_points\n",
    ")\n",
    "print(\"✓ Collision points match!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mesh to /workspaces/studio/framework/meshlyP/python/mesh_physics_external.zip\n",
      "  Zip file size: 1483 bytes\n",
      "  Files in zip: ['arrays/cell_types/array.bin', 'arrays/cell_types/metadata.json', 'arrays/index_sizes/array.bin', 'arrays/index_sizes/metadata.json', 'vertices.bin', 'indices.bin', 'metadata.json']\n",
      "  Has embedded packables/: False\n",
      "\n",
      "External assets collected: 1\n",
      "  4b9ba04bbd1b4482...: 1086 bytes (physics Packable)\n"
     ]
    }
   ],
   "source": [
    "# Using assets parameter to externalize nested Packables\n",
    "# This is useful for external storage, caching, or deduplication\n",
    "import zipfile\n",
    "\n",
    "# Save with assets dict - nested Packables are stored externally (not in zip)\n",
    "external_assets: dict[str, bytes] = {}\n",
    "physics_zip_external = Path(\"./mesh_physics_external.zip\")\n",
    "mesh_with_physics.save_to_zip(physics_zip_external, assets=external_assets)\n",
    "\n",
    "print(f\"Saved mesh to {physics_zip_external.absolute()}\")\n",
    "print(f\"  Zip file size: {physics_zip_external.stat().st_size} bytes\")\n",
    "\n",
    "# Show what's in the zip - note: NO packables/ folder!\n",
    "with zipfile.ZipFile(physics_zip_external) as zf:\n",
    "    print(f\"  Files in zip: {zf.namelist()}\")\n",
    "    has_packables = any('packables/' in n for n in zf.namelist())\n",
    "    print(f\"  Has embedded packables/: {has_packables}\")\n",
    "\n",
    "print(f\"\\nExternal assets collected: {len(external_assets)}\")\n",
    "for checksum, data in external_assets.items():\n",
    "    print(f\"  {checksum[:16]}...: {len(data)} bytes (physics Packable)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded with dict provider:\n",
      "  Physics mass: 5.0\n",
      "  Physics friction: 0.3\n",
      "  Fetching 4b9ba04bbd1b4482...\n",
      "\n",
      "Loaded with callable provider:\n",
      "  Fetches triggered: 1\n",
      "  Physics mass: 5.0\n",
      "\n",
      "✓ External assets demo complete!\n"
     ]
    }
   ],
   "source": [
    "# Load using the assets dict as provider\n",
    "loaded_external = MeshWithPhysics.load_from_zip(physics_zip_external, assets=external_assets)\n",
    "print(f\"Loaded with dict provider:\")\n",
    "print(f\"  Physics mass: {loaded_external.physics.mass}\")\n",
    "print(f\"  Physics friction: {loaded_external.physics.friction}\")\n",
    "\n",
    "# Load using a callable provider (simulates remote fetch)\n",
    "fetch_count = [0]\n",
    "def fetch_asset(checksum: str) -> bytes:\n",
    "    fetch_count[0] += 1\n",
    "    print(f\"  Fetching {checksum[:16]}...\")\n",
    "    return external_assets[checksum]\n",
    "\n",
    "loaded_lazy = MeshWithPhysics.load_from_zip(physics_zip_external, assets=fetch_asset)\n",
    "print(f\"\\nLoaded with callable provider:\")\n",
    "print(f\"  Fetches triggered: {fetch_count[0]}\")\n",
    "print(f\"  Physics mass: {loaded_lazy.physics.mass}\")\n",
    "\n",
    "# Clean up\n",
    "physics_zip_external.unlink()\n",
    "print(f\"\\n✓ External assets demo complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Extract/Reconstruct with Nested Packables\n",
    "\n",
    "The `extract()` and `reconstruct()` methods handle nested Packables by encoding them as assets with checksum references. This is useful for:\n",
    "- Serializing to JSON (data) + binary blobs (assets)\n",
    "- Remote execution where assets are transferred separately\n",
    "- Caching and deduplication of shared Packables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created SceneObject 'my_cube' with mesh (8 verts)\n"
     ]
    }
   ],
   "source": [
    "# Create a Pydantic model that contains a Mesh (Packable)\n",
    "class SceneObject(BaseModel):\n",
    "    \"\"\"A scene object containing a mesh and transform data.\"\"\"\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    \n",
    "    name: str = Field(..., description=\"Object name\")\n",
    "    mesh: Mesh = Field(..., description=\"The mesh geometry\")\n",
    "    position: np.ndarray = Field(..., description=\"Position in 3D space\")\n",
    "    rotation: np.ndarray = Field(..., description=\"Rotation (quaternion)\")\n",
    "    scale: float = Field(1.0, description=\"Uniform scale\")\n",
    "\n",
    "# Create a scene object with a mesh\n",
    "scene_obj = SceneObject(\n",
    "    name=\"my_cube\",\n",
    "    mesh=Mesh(vertices=vertices, indices=indices),\n",
    "    position=np.array([1.0, 2.0, 3.0], dtype=np.float32),\n",
    "    rotation=np.array([0.0, 0.0, 0.0, 1.0], dtype=np.float32),  # identity quaternion\n",
    "    scale=2.0\n",
    ")\n",
    "\n",
    "print(f\"Created SceneObject '{scene_obj.name}' with mesh ({scene_obj.mesh.vertex_count} verts)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data (JSON-serializable):\n",
      "  Keys: ['name', 'mesh', 'position', 'rotation', 'scale']\n",
      "  name: my_cube\n",
      "  scale: 2.0\n",
      "  mesh: {'$ref': '1699137d50666dbe'}\n",
      "  position: {'$ref': '21849fc3b8888dd5'}\n",
      "\n",
      "Assets (binary blobs):\n",
      "  Number of assets: 3\n",
      "  1699137d50666dbe...: 1416 bytes\n",
      "  21849fc3b8888dd5...: 123 bytes\n",
      "  1f9da9f6ca9a12cb...: 123 bytes\n"
     ]
    }
   ],
   "source": [
    "# Extract the scene object - this separates JSON-serializable data from binary assets\n",
    "extracted = Packable.extract(scene_obj)\n",
    "\n",
    "print(\"Extracted data (JSON-serializable):\")\n",
    "print(f\"  Keys: {list(extracted.data.keys())}\")\n",
    "print(f\"  name: {extracted.data['name']}\")\n",
    "print(f\"  scale: {extracted.data['scale']}\")\n",
    "print(f\"  mesh: {extracted.data['mesh']}\")  # This is a $ref to the encoded Packable\n",
    "print(f\"  position: {extracted.data['position']}\")  # This is a $ref to the encoded array\n",
    "\n",
    "print(f\"\\nAssets (binary blobs):\")\n",
    "print(f\"  Number of assets: {len(extracted.assets)}\")\n",
    "for checksum, data in extracted.assets.items():\n",
    "    print(f\"  {checksum[:16]}...: {len(data)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON representation of extracted data:\n",
      "{\n",
      "  \"name\": \"my_cube\",\n",
      "  \"mesh\": {\n",
      "    \"$ref\": \"1699137d50666dbe\"\n",
      "  },\n",
      "  \"position\": {\n",
      "    \"$ref\": \"21849fc3b8888dd5\"\n",
      "  },\n",
      "  \"rotation\": {\n",
      "    \"$ref\": \"1f9da9f6ca9a12cb\"\n",
      "  },\n",
      "  \"scale\": 2.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# The data dict is JSON-serializable (can be sent over network, stored in DB, etc.)\n",
    "json_str = json.dumps(extracted.data, indent=2)\n",
    "print(\"JSON representation of extracted data:\")\n",
    "print(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed SceneObject:\n",
      "  name: my_cube\n",
      "  scale: 2.0\n",
      "  position: [1. 2. 3.]\n",
      "  mesh type: Mesh\n",
      "  mesh vertices: 8\n",
      "\n",
      "✓ Reconstructed data matches original!\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct the scene object from data + assets\n",
    "# The Pydantic schema tells reconstruct() that 'mesh' is a Mesh type,\n",
    "# so it knows to decode the Packable bytes back into a Mesh instance\n",
    "reconstructed = Packable.reconstruct(SceneObject, extracted.data, extracted.assets)\n",
    "\n",
    "print(\"Reconstructed SceneObject:\")\n",
    "print(f\"  name: {reconstructed.name}\")\n",
    "print(f\"  scale: {reconstructed.scale}\")\n",
    "print(f\"  position: {reconstructed.position}\")\n",
    "print(f\"  mesh type: {type(reconstructed.mesh).__name__}\")\n",
    "print(f\"  mesh vertices: {reconstructed.mesh.vertex_count}\")\n",
    "\n",
    "# Verify the data matches\n",
    "np.testing.assert_array_almost_equal(reconstructed.position, scene_obj.position)\n",
    "np.testing.assert_array_almost_equal(reconstructed.mesh.vertices, scene_obj.mesh.vertices)\n",
    "print(\"\\n✓ Reconstructed data matches original!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy Loading with Callbacks\n",
    "\n",
    "When using a callable instead of a dict for assets, `reconstruct()` returns a `LazyModel` that only fetches assets when fields are accessed. This is useful for large meshes or remote storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lazy model (no assets fetched yet)...\n",
      "  Type: LazyModel\n",
      "  Fetches so far: 0\n",
      "\n",
      "Accessing 'name': my_cube\n",
      "  Fetches so far: 0\n",
      "\n",
      "Accessing 'position':\n",
      "  Fetching asset 21849fc3b8888dd5...\n",
      "  Value: [1. 2. 3.]\n",
      "  Fetches so far: 1\n",
      "\n",
      "Accessing 'mesh':\n",
      "  Fetching asset 1699137d50666dbe...\n",
      "  Type: Mesh, vertices: 8\n",
      "  Total fetches: 2\n"
     ]
    }
   ],
   "source": [
    "# Simulate a remote asset fetcher with logging\n",
    "fetch_log = []\n",
    "\n",
    "def asset_fetcher(checksum: str) -> bytes:\n",
    "    \"\"\"Simulates fetching from remote storage.\"\"\"\n",
    "    fetch_log.append(checksum)\n",
    "    print(f\"  Fetching asset {checksum[:16]}...\")\n",
    "    return extracted.assets[checksum]\n",
    "\n",
    "# Reconstruct with callable - returns LazyModel\n",
    "print(\"Creating lazy model (no assets fetched yet)...\")\n",
    "lazy_scene = Packable.reconstruct(SceneObject, extracted.data, asset_fetcher)\n",
    "print(f\"  Type: {type(lazy_scene).__name__}\")\n",
    "print(f\"  Fetches so far: {len(fetch_log)}\")\n",
    "\n",
    "# Access scalar field - no fetch needed\n",
    "print(f\"\\nAccessing 'name': {lazy_scene.name}\")\n",
    "print(f\"  Fetches so far: {len(fetch_log)}\")\n",
    "\n",
    "# Access array field - triggers fetch\n",
    "print(f\"\\nAccessing 'position':\")\n",
    "pos = lazy_scene.position\n",
    "print(f\"  Value: {pos}\")\n",
    "print(f\"  Fetches so far: {len(fetch_log)}\")\n",
    "\n",
    "# Access mesh field - triggers fetch of the Packable\n",
    "print(f\"\\nAccessing 'mesh':\")\n",
    "m = lazy_scene.mesh\n",
    "print(f\"  Type: {type(m).__name__}, vertices: {m.vertex_count}\")\n",
    "print(f\"  Total fetches: {len(fetch_log)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed mesh_with_physics.zip\n"
     ]
    }
   ],
   "source": [
    "# Clean up the physics mesh file\n",
    "if physics_zip_path.exists():\n",
    "    physics_zip_path.unlink()\n",
    "    print(f\"Removed {physics_zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Using Callbacks for Nested Packables\n",
    "\n",
    "When working with meshes that contain nested Packables (like our `TexturedMesh` with `PhysicsProperties`), you can use callbacks to implement custom caching, storage, or deduplication strategies.\n",
    "\n",
    "The callback types are:\n",
    "- **`on_packable` (save)**: `Callable[[Packable, str], None]` - called with `(packable, checksum)` when saving\n",
    "- **`on_packable` (load)**: `Callable[[Type[Packable], str], Optional[Packable]]` - called with `(packable_type, checksum)` when loading; return `None` to fall back to embedded data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Deduplication Example\n",
    "\n",
    "When multiple meshes share the same nested Packable data, the cache automatically deduplicates them using SHA256 hashes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Jax Conversion Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted skinned mesh to JAX arrays, vertex dtype: float32\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import jax\n",
    "\n",
    "    jax_skinned_mesh = skinned_mesh.convert_to(\"jax\")\n",
    "    print(f\"Converted skinned mesh to JAX arrays, vertex dtype: {jax_skinned_mesh.vertices.dtype}\")\n",
    "except ImportError:\n",
    "    print(\"JAX not available - skipping conversion example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Complete!\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Creating custom Mesh subclasses with additional numpy arrays\n",
    "- Working with nested dictionaries containing arrays\n",
    "- Using BaseModel instances with arrays inside dictionaries\n",
    "- **Nested Packables**: Direct Packable fields are now supported in `save_to_zip`/`load_from_zip`\n",
    "- **Extract/Reconstruct**: How nested Packables are serialized as `$ref` checksums and reconstructed using Pydantic schema type info\n",
    "- **Lazy Loading**: Using callable asset fetchers for on-demand loading"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
